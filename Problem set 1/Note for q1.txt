(1)
The answer is (A). LOO-CV uses each data point once as a validation set, while the remaining n-1 observations are used for training. Hence, you train n models and the required computational budget is proportional to the size of your dataset, making it infeasible on larger ones. 

(2)
N = 5000 | N_val = 500 | N_CV = 4500 |Lambda {10e-2, 10e-1, 10e0, 10e1} (regularization strength) | K = 5

Assumptions for model train/test: Training takes N_train^2 | Testing takes ½ N_test^2 | All other things neglible

K = 5 folds --> Train = 80% = 4/5 * 4500 =3600 --> Test = 4500-3600 = 1/5 4500 = 900

For K = 1: 3600^2 = 12.960.000 units of time, Test = ½ * 900^2 = 405.000 units of time 

CV has K = 5 for each lambda: ==> 5 x (12.960.000 + 405.000) = 66.825.000
Hence for 4 different lambda values: ==> 4 x 66.825.000 = 267.300.000 units of time.

Final hold-out on D_cv and D_val:
Selected optimal lambda and trains on D_cv and validates on D_val, i.e.
D_cv = 4500^2 = 20.250.000 | D_val = ½ x 500^2 = 125.000
==> Total: 20.375.000 + 267.300.000 units of time.


(3)
Simply read off the distances in the columns and take the k=3 nearest neighbours (e.g. sort ascending) and determine their class by the most frequent (majority). 
Using this, specify if the point is correctly classified (e.g. a red is actually determined as red is correct, otherwise incorrect).


(4)
Compute Euclidean distance ( sqrt([x_i - mu_j,x]^2 + [y_i - mu_j,y]^2) ) from each point to each cluster...
Assign point to cluster that is closest.
Update cluster points as the mean of all points assigned to itself.
Keep going until stabilized,  (not needed for exercise)

(5)
Definition of an expectation is E[ax] = int^inf_-inf (ax) f(x)dx = a * int^inf_-inf xf(x)dx, do for E[ax+by] = ... (ax+by)f_x,y(x,y)dxdy ==> Seperate them into two different integrals
==> put the constants outside ==> You now have the a and b outside and the definition of an expectation inside.

(6)
==========
18 red
18 black
2 green
TOTAL 38
==========
BET IS ON RED OF 1$, PROFIT IS 1$.
ELSE LOSE 1$ (your bet)
The expected value per bet or earnings per bet is EVPB = (P_win x $_win) + (P_loss x $_loss) = (18/38 x 1$) + (20/38 x (-1$)) = 18/38 - 20/38 = -2/38 ~= -0.053$

(7) 
Bayes: P(BC|M_p) = P(M_p|BC)P(BC)/P(M_p)...
P(M_p) = P(M_p|BC)P(BC) + P(M_p|~BC)P(~BC) (~ means not, i.e. not have breast cancer, which is P(~BC) = 99.3% and P(M_p|~BC) = 8%
       = 0.90 * 0.07 + 0.993 * 0.08 = 0.07944 + 0.0063 = 0.08574

P(BC|M_p) = (0.9 * 0.007) / 0.08574 ~= 0.074 aka 7.4%!

(8)
Use the discrete-time convultion formula: y(n) = Sum^inf_k=-inf x(k)h(n-k)
Then... Find what values x(n) have if the given range, ie. for n in {0,1,2,3,4,5,6}, and it is 1 for the whole spectrum of h.
Calculate the convolution by starting from the lowest possible n value, ie y(-2)=0, y(-1)=0, ..., y(8) --> WHY 8??? WELL LET ME TELL YOU!!
https://imgur.com/a/hJLZy7s !!!!

(9.1)
Write out analog sinusoid x(t) = A cos(2pi*F_0*t+theta), -inf < t < inf as a complex exponential signal (easy, check slides and insert... Fourier)

(9.2) What are the Fourier coefficients (c_k) for the analog sinusoid? (Sketch the magnitude and phase spectrum)

(10) PCA
Explained variance of P1 and P2 is (Look in S):

Take the sum of the diagonal elements squared and divide em with the squared variance of the X principal components you wish to find... P1 and P2 e.g
sigma^2_1 + sigma^2_2 / Sum_n=1^4 sigma^2_n = Explained variance of 1 and 2. (~= 96.52% and 3.31% so total of 99.83%)

(11.1)
https://imgur.com/a/ucvfXrO

(11.2)
https://imgur.com/a/bzCXkco